{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "819eb27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import pickle as pk\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 5\n",
    "VALIDATION_SPLIT = 0.02\n",
    "    \n",
    "INPUT_DATA = \"../data/problem_1_train.dat\"\n",
    "MODEL_NAME = \"model_problem_1.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47a47a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line:  0\n",
      "Line:  10000\n",
      "Line:  20000\n",
      "Line:  30000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(39907, 39907, {0, 1})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list()\n",
    "sequences = list()\n",
    "alphabet = set()\n",
    "\n",
    "with open(INPUT_DATA, \"rt\") as inf:\n",
    "    inf.readline() # kill the header\n",
    "    for i, line in enumerate(inf):\n",
    "        if len(line.strip()) == 0:\n",
    "            continue\n",
    "        line = line.split()\n",
    "        labels.append(int(line[0]))\n",
    "        sequences.append(list( int(x) for x in line[2:] ))\n",
    "        alphabet = alphabet.union(set( int(x) for x in line[2:] ))\n",
    "        if i % int(10e3) == 0:\n",
    "            print(\"Line: \", i)\n",
    "len(labels), len(sequences), alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f367967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39907, 8), (39907, 1), {0: 0, 1: 1})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = np.array(sequences)\n",
    "labels = np.array(labels).reshape(-1, 1)\n",
    "alphabet_map = {symbol: index for index, symbol in enumerate(alphabet)}\n",
    "\n",
    "pk.dump(alphabet_map, open(\"alphabet_mapping.pk\", \"wb\"))\n",
    "\n",
    "sequences.shape, labels.shape, alphabet_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62b38998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  [[1 0 1 1 0 1 1 1]\n",
      " [1 0 0 1 1 1 1 1]\n",
      " [1 1 1 0 0 1 1 0]]\n",
      "Shape:  (39907, 8)\n",
      "After:  [[[0. 1.]\n",
      "  [1. 0.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]\n",
      "  [1. 0.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]]\n",
      "\n",
      " [[0. 1.]\n",
      "  [1. 0.]\n",
      "  [1. 0.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]]\n",
      "\n",
      " [[0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]\n",
      "  [1. 0.]\n",
      "  [1. 0.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]\n",
      "  [1. 0.]]]\n",
      "Shape:  (39907, 8, 2)\n"
     ]
    }
   ],
   "source": [
    "sequences_one_hot = np.zeros((sequences.shape[0], sequences.shape[1], len(alphabet)))\n",
    "for i, seq in enumerate(sequences):\n",
    "    for j, sym in enumerate(seq):\n",
    "        sequences_one_hot[i, j, alphabet_map[sym]] = 1\n",
    "print(\"Before: \", sequences[:3])\n",
    "print(\"Shape: \", sequences.shape)\n",
    "print(\"After: \", sequences_one_hot[:3])\n",
    "print(\"Shape: \", sequences_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa8a9110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_shape):\n",
    "    OUTPUT_DIM = 1 # sigmoid output\n",
    "\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    \n",
    "    x = Bidirectional(LSTM(4))(input_layer)\n",
    "    x_out = Dense(OUTPUT_DIM, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(input_layer, x_out)\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=\"adam\",\n",
    "        metrics=[\"binary_crossentropy\"]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b6cd0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1223/1223 [==============================] - 5s 3ms/step - loss: 0.5146 - binary_crossentropy: 0.5146 - val_loss: 0.1856 - val_binary_crossentropy: 0.1856\n",
      "Epoch 2/5\n",
      "1223/1223 [==============================] - 3s 2ms/step - loss: 0.0921 - binary_crossentropy: 0.0921 - val_loss: 0.0273 - val_binary_crossentropy: 0.0273\n",
      "Epoch 3/5\n",
      "1223/1223 [==============================] - 3s 2ms/step - loss: 0.0159 - binary_crossentropy: 0.0159 - val_loss: 0.0099 - val_binary_crossentropy: 0.0099\n",
      "Epoch 4/5\n",
      "1223/1223 [==============================] - 3s 2ms/step - loss: 0.0068 - binary_crossentropy: 0.0068 - val_loss: 0.0047 - val_binary_crossentropy: 0.0047\n",
      "Epoch 5/5\n",
      "1223/1223 [==============================] - 3s 2ms/step - loss: 0.0034 - binary_crossentropy: 0.0034 - val_loss: 0.0024 - val_binary_crossentropy: 0.0024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7faa104b47f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(( sequences_one_hot.shape[1], sequences_one_hot.shape[2] ))\n",
    "\n",
    "es = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=1,\n",
    "    mode=\"auto\")\n",
    "\n",
    "model.fit(\n",
    "    sequences_one_hot, \n",
    "    labels,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3f99c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bff369c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
