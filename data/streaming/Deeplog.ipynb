{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6996da5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-24 14:53:27.995312: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Reshape\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Bidirectional\n",
    "from tensorflow.keras.layers import Lambda, Flatten\n",
    "import keras.backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "VALIDATION_SPLIT=0.05\n",
    "\n",
    "MAX_LINESIZE = 20 # this is the maximum length of a line. We need this for zero padding\n",
    "ZERO_PADDING_CHAR = \"X\"\n",
    "INPUT_READER_BATCH_SIZE = int(1e5)\n",
    "NEUTRAL_LABEL = \"0\"\n",
    "\n",
    "TRAIN_FILEPATH = os.path.join(\"july_week_5_train.dat.encoded.dat.extracted_sequences.dat\")\n",
    "TEST_FILEPATH = os.path.join(\"july_week_5_test.dat.encoded.dat.extracted_sequences.dat\")\n",
    "LABEL_FILEPATH = os.path.join(\"july_week_5_test.dat.labels.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64842a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(INPUT_DIM, OUTPUT_DIM, N_SEQUENCES):\n",
    "    INPUT_SHAPE = (INPUT_DIM, N_SEQUENCES)\n",
    "    OUTPUT_SHAPE = (OUTPUT_DIM,)\n",
    "\n",
    "    input_layer = Input(shape=INPUT_SHAPE)\n",
    "    rnn_layer = LSTM(int(INPUT_DIM * 1.5))\n",
    "    output_layer = Dense(int(OUTPUT_DIM), activation=\"softmax\")\n",
    "\n",
    "    x = rnn_layer(input_layer)\n",
    "    x_out = output_layer(x)\n",
    "\n",
    "    model = Model(input_layer, x_out)\n",
    "    model.compile(\n",
    "      loss=\"cross_entropy\",\n",
    "      optimizer=\"adam\",\n",
    "      metrics=[\"cross_entropy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def get_batch_of_input(infile, n_lines):\n",
    "    \"\"\"Only if a file is too large to fit into memory\"\"\"\n",
    "    res = list()\n",
    "    for _ in range(n_lines):\n",
    "        line = infile.readline()\n",
    "        if line==\"\":\n",
    "            return None\n",
    "        res.append(np.array( line.split()[2:] ))\n",
    "    return np.array(res)\n",
    "\n",
    "def get_label(line):\n",
    "    symbols = set( line.split() )\n",
    "    if len(symbols > 1) or not NEUTRAL_LABEL in symbols:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def read_input(infile, label_file=None, input_alph=None, MAXLINES=int(1e6)):\n",
    "    res = list()\n",
    "    labels = None \n",
    "    if label_file:\n",
    "        labels = list()\n",
    "    \n",
    "    alphabet = dict() if input_alph is None else input_alph\n",
    "    if not ZERO_PADDING_CHAR in alphabet:\n",
    "        alphabet[ZERO_PADDING_CHAR] = len(alphabet)\n",
    "                \n",
    "    for i, line in enumerate(infile):\n",
    "        if i == MAXLINES:\n",
    "            break\n",
    "            \n",
    "        linesplit = line.split()[2:]\n",
    "        line = list()\n",
    "        for x in linesplit:\n",
    "            if not x in alphabet:\n",
    "                alphabet[x] = len(alphabet)\n",
    "            line.append( alphabet[x] )\n",
    "        if len(line) < MAX_LINESIZE:\n",
    "            line.extend( [ alphabet[ZERO_PADDING_CHAR] ] * (MAX_LINESIZE - len(line)) )\n",
    "        res.append( np.array(line) )\n",
    "        \n",
    "        if label_file:\n",
    "            label_line = label_file.readline()\n",
    "            labels.append( get_label(label_line) )\n",
    "\n",
    "    reverse_alphabet = {v:k for k,v in alphabet.items()}\n",
    "    labels = np.array(labels) if labels is not None else labels\n",
    "    return np.array(res), alphabet, reverse_alphabet, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5064bb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 2 3 1 4 5 1 5 6 1 1 7 5 5 6 1 6 8 4 1]\n",
      " [2 3 1 4 5 1 5 6 1 1 7 5 5 6 1 6 8 4 1 6]] (1000000, 20)\n"
     ]
    }
   ],
   "source": [
    "trainfile = open(TRAIN_FILEPATH, \"rt\")\n",
    "train_header = trainfile.readline()\n",
    "x_train, alphabet, _, _ = read_input(infile=trainfile)\n",
    "print(x_train[:3], x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0b3d736",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(len(alphabet), len(alphabet), MAX_LINESIZE)\n",
    "\n",
    "es = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=1,\n",
    "    mode=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac72922",
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration in range(EPOCHS):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbd2d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "testfile = open(TRAIN_FILEPATH, \"rt\")\n",
    "test_header = testfile.readline()\n",
    "\n",
    "x_test, alphabet, reverse_alphabet = read_input(infile=testfile, input_alph=alphabet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b39ca1",
   "metadata": {},
   "source": [
    "for ATTACK in [DOS, SCAN44, SCAN11, NERISBOTNET, ANOMALYSPAM]:\n",
    "\n",
    "    base_dir = os.path.join(BASE_DIR_MALIGN, ATTACK)\n",
    "    MALIGN_RANGE = pickle.load(open(os.path.join(base_dir, \"X_seq.pk\"), \"rb\")).shape[0]\n",
    "    SAMPLES_DRAWN_MALIGN = np.random.choice(MALIGN_RANGE, size=min(MAX_NGRAMS_TRAIN, MALIGN_RANGE), replace=False)\n",
    "    \n",
    "    X_test_malign_seq = load_and_sample(\"X_seq.pk\", SAMPLES_DRAWN_MALIGN, base_dir)\n",
    "    X_test_malign_src = load_and_sample(\"X_src.pk\", SAMPLES_DRAWN_MALIGN, base_dir)\n",
    "    X_test_malign_dst = load_and_sample(\"X_dst.pk\", SAMPLES_DRAWN_MALIGN, base_dir)\n",
    "    X_test_malign_conn = load_and_sample(\"X_conn.pk\", SAMPLES_DRAWN_MALIGN, base_dir)\n",
    "    \n",
    "    if channel == \"seq\":\n",
    "      X_test_malign = X_test_malign_seq\n",
    "    elif channel == \"src\":\n",
    "      X_test_malign = X_test_malign_src\n",
    "    elif channel == \"dst\":\n",
    "      X_test_malign = X_test_malign_dst\n",
    "    elif channel == \"conn\":\n",
    "      X_test_malign = X_test_malign_conn\n",
    "    else:\n",
    "      X_test_malign = np.concatenate((X_test_malign_seq, X_test_malign_src, X_test_malign_dst, X_test_malign_conn), axis=-1)\n",
    "\n",
    "    X_test_malign = X_test_malign.reshape(X_test_malign.shape[0], -1)\n",
    "\n",
    "    model.fit(\n",
    "      X_benign_train, \n",
    "      X_benign_train,\n",
    "      batch_size=BATCH_SIZE,\n",
    "      epochs=EPOCHS,\n",
    "      validation_split=VALIDATION_SPLIT,\n",
    "      callbacks=[es]\n",
    "    )\n",
    "\n",
    "    X_test_benign_pred = model.predict(X_benign_test)\n",
    "    X_test_malign_pred = model.predict(X_test_malign)\n",
    "\n",
    "    diffs_benign = np.mean(np.abs(X_benign_test.reshape(X_benign_test.shape[0], -1) - X_test_benign_pred), axis=1)\n",
    "    diffs_malign = np.mean(np.abs(X_test_malign.reshape(X_test_malign.shape[0], -1) - X_test_malign_pred), axis=1)\n",
    "\n",
    "    from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "    y_true = np.array(len(diffs_benign) * [0] + len(diffs_malign) * [1]).reshape(-1)\n",
    "    score = np.vstack((np.array(diffs_benign).reshape(-1, 1), np.array(diffs_malign).reshape(-1, 1))).reshape(-1)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, score)\n",
    "    roc_auc = roc_auc_score(y_true, score)\n",
    "\n",
    "    if not ATTACK in results:\n",
    "      results[ATTACK] = list()\n",
    "    results[ATTACK].append(roc_auc)\n",
    "\n",
    "pickle.dump(results, open(\"aucs_vanilla_ae_{}_{}.pk\".format(stats, channel), \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
