{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ccbdb0b-0508-494a-a8a8-c0d4ff724e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 13:43:15.815904: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Reshape\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Embedding\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pickle as pk\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 2\n",
    "VALIDATION_SPLIT = 0.02\n",
    "\n",
    "train_data_path = \"train_data.pk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c059c361-4927-4f3d-9988-f0dc5ff78596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2989284"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pk.load(open(train_data_path, \"rb\"))\n",
    "X_train = train_data[\"X\"]\n",
    "even_dict = train_data[\"event_mapping\"]\n",
    "\n",
    "alphabet_size = train_data[\"alphabet_size\"]\n",
    "\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "401c7fa2-7629-4673-81bd-a9784509bc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val = train_test_split(X_train, test_size=VALIDATION_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26d4a0f2-7094-462b-b15f-af6b316755db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_shape, alphabet_size):\n",
    "    OUTPUT_DIM = alphabet_size # sigmoid output\n",
    "\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = Embedding(alphabet_size, 20)(input_layer)\n",
    "    x = LSTM(128)(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dense(OUTPUT_DIM, activation=\"softmax\")(x)\n",
    "    model = Model(input_layer, x)\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=\"adam\",\n",
    "        metrics=[\"categorical_crossentropy\"]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7051a418-ef36-44dc-a5fc-8a2dbb476c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([10, 321]), 321)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model((1,), alphabet_size)\n",
    "\n",
    "model(np.array(X_train[0])).shape, alphabet_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46fcc862-beda-40a9-9f05-46c3520e4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# because we have arrays of different length we have to use the fit_generator() method\n",
    "import copy\n",
    "\n",
    "def data_generator():\n",
    "    global X_train\n",
    "    global alphabet_size\n",
    "    \n",
    "    idx = 0\n",
    "    while True:\n",
    "        if idx == len(X_train):\n",
    "            idx = 0\n",
    "        x_src = copy.copy(X_train[idx])\n",
    "        x_tgt = np.zeros((len(X_train[idx])+1, alphabet_size))\n",
    "        for i, x in enumerate(x_src):\n",
    "            x_tgt[i, x] = 1\n",
    "        x_src.insert(0, even_dict[\"<SOS>\"])\n",
    "        x_tgt[-1, even_dict[\"<EOS>\"]] = 1\n",
    "\n",
    "        #print(x_src)\n",
    "        #for i in range(x_tgt.shape[0]):\n",
    "        #    print(np.argmax(x_tgt[i]))\n",
    "        \n",
    "        yield np.array(x_src), x_tgt\n",
    "        idx += 1\n",
    "\n",
    "def val_generator():\n",
    "    global X_val\n",
    "    global alphabet_size\n",
    "    \n",
    "    idx = 0\n",
    "    while True:\n",
    "        if idx == len(X_val):\n",
    "            idx = 0\n",
    "        x_src = copy.copy(X_val[idx])\n",
    "        x_tgt = np.zeros((len(X_val[idx])+1, alphabet_size))\n",
    "        for i, x in enumerate(x_src):\n",
    "            x_tgt[i, x] = 1\n",
    "        x_src.insert(0, even_dict[\"<SOS>\"])\n",
    "        x_tgt[-1, even_dict[\"<EOS>\"]] = 1\n",
    "        \n",
    "        yield np.array(x_src), x_tgt\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e0ea404-37aa-4a06-bb1a-93f8609dcf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = data_generator()\n",
    "for i, x in enumerate(test_gen):\n",
    "    if i == 1:    \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "649a0fba-d6d4-45db-85b4-cd12e4088aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "91546/91546 [==============================] - 241s 3ms/step - loss: 1.0448 - categorical_crossentropy: 1.0448 - val_loss: 0.9975 - val_categorical_crossentropy: 0.9975\n",
      "Epoch 2/2\n",
      "91546/91546 [==============================] - 229s 3ms/step - loss: 0.9936 - categorical_crossentropy: 0.9936 - val_loss: 0.9922 - val_categorical_crossentropy: 0.9922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fcca01eb0d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=4,\n",
    "    mode=\"auto\")\n",
    "\n",
    "data_gen = data_generator()\n",
    "val_gen = val_generator()\n",
    "\n",
    "model.fit(\n",
    "    data_gen,\n",
    "    steps_per_epoch=int(len(X_train) / BATCH_SIZE),\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=len(X_val),\n",
    "    #validation_split=VALIDATION_SPLIT,\n",
    "    callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75ffda14-b2f5-4174-ada1-6bd61d57f109",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
